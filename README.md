---

# âœ… **README.md**

---

# ğŸ–¥ï¸ **Serveur TCP Mono-thread vs Multi-thread en C (Projet SystÃ¨mes dâ€™Exploitation AvancÃ©s)**

**Auteur : Walid Ben Touhami**
**Technologies : C11 Â· POSIX Threads Â· Python3 Â· Linux Ubuntu 24.04 Â· GitHub CI/CD**

---

## ğŸ“Œ **RÃ©sumÃ© du projet**

Ce projet met en Å“uvre et compare **deux architectures complÃ¨tes de serveurs TCP** en C :

* âœ” **serveur_mono** â†’ modÃ¨le sÃ©quentiel, mono-thread
* âœ” **serveur_multi** â†’ modÃ¨le concurrent basÃ© sur :

  * un **thread acceptor**
  * un **pool fixe de 8 workers**
  * une **queue FIFO thread-safe** (mutex + condition variables)

Chaque requÃªte simule un **traitement intensif** :
â†’ 100 000 calculs `sqrt()` + dÃ©lai alÃ©atoire 10â€“100 ms.
Cela permet d'obtenir une comparaison **rÃ©aliste** mono vs multi-thread.

Le projet inclut Ã©galement :

* un **client de stress Python**
* un **benchmark complet** (latence, throughput, CPU, RAM)
* des **graphiques dâ€™analyse**
* une **CI/CD GitHub Actions**
* un **gÃ©nÃ©rateur automatique de slides PowerPoint**
* un **rapport LaTeX** pour soutenance

Ce projet constitue un cas dâ€™Ã©tude complet en **programmation systÃ¨me, threading, performance et architecture logicielle**.

---

## ğŸ“‚ **Structure du projet**

```
server_project/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ serveur_mono.c
â”‚   â”œâ”€â”€ serveur_multi.c
â”‚   â”œâ”€â”€ queue.c
â”‚   â””â”€â”€ queue.h
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_queue.c         # tests unitaires FIFO
â”‚
â”œâ”€â”€ benchmark/
â”‚   â”œâ”€â”€ client.py            # client de stress
â”‚   â”œâ”€â”€ benchmark.py         # benchmark global
â”‚   â””â”€â”€ plot_results.py      # graphiques
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ rapport.tex
â”‚   â””â”€â”€ diagrammes UML (optionnel)
â”‚
â”œâ”€â”€ generate_ppt.py          # gÃ©nÃ©ration automatique PPTX
â”œâ”€â”€ Makefile                 # build Pro (debug, test, sanitizer, runâ€¦)
â”œâ”€â”€ INSTALL.md               # installation & exÃ©cution
â””â”€â”€ README.md                # ce fichier
```

---

# ğŸš€ **Compilation & exÃ©cution**

## ğŸ”§ **Compilation standard**

```
make
```

## ğŸ§¹ Nettoyage

```
make clean
```

## ğŸ› Mode debug (ASan + UBSan)

```
make debug
```

---

# â–¶ï¸ **ExÃ©cution des serveurs**

## Mono-thread

```
make run_mono
```

Disponible sur **port 5050**.

## Multi-thread

```
make run_multi
```

Disponible sur **port 5051**.

## ArrÃªt des serveurs

```
make kill_servers
```

---

# ğŸ§ª **Tests unitaires**

```
make test
```

Teste entiÃ¨rement la **file FIFO thread-safe** (mutex + cond + shutdown).

Sortie typique :

```
[TEST] consumer received 1000 items
[TEST] test_queue terminÃ©.
```

---

# ğŸ“Š **Benchmark complet (Python)**

Le benchmark exÃ©cute :

* 10, 50, 100, 200, 300 clients simultanÃ©s
* Mesure :

  * latence moyenne
  * P95, P99
  * throughput (req/s)
  * CPU total & par cÅ“ur (psutil)
  * consommation mÃ©moire (RSS)
* Export :

  * JSON
  * Excel
* GÃ©nÃ¨re 6 graphiques :

  * dÃ©bit vs charge
  * latence P99 vs clients
  * heatmap CPU
  * consommation mÃ©moire
  * speedup multi-thread
  * saturation des workers

### ExÃ©cution :

```
python3 benchmark/benchmark.py
```

---

# ğŸ“‘ **Rapport LaTeX (soutenance)**

Le dossier `docs/` contient :

* un rapport `.tex` complet (plan 5â€“7 pages)
* sections "architecture", "analyse des rÃ©sultats", "limites", "perspectives"
* espaces rÃ©servÃ©s pour les graphiques produits par le benchmark

Compilation :

```
cd docs
pdflatex rapport.tex
```

---

# ğŸï¸ **PrÃ©sentation PowerPoint (gÃ©nÃ©rÃ©e automatiquement)**

Le script Python gÃ©nÃ¨re un **PPTX acadÃ©mique 16:9 complet** :

```
python3 generate_ppt.py
```

Sortie :

```
presentation_server_project.pptx
```

---

# ğŸ§  **Architecture conceptuelle**

### **Mono-thread**

```
while (1) {
    client = accept();
    traiter(client);
}
```

â†’ Simple mais saturÃ© dÃ¨s ~10 connexions.

### **Multi-thread**

```
acceptor â†’ queue â†’ workers (Ã—8)
```

â†’ ScalabilitÃ©, rÃ©duction du temps de rÃ©ponse, meilleure utilisation CPU.

---

# ğŸ“ˆ **RÃ©sultats attendus**

* Le multi-thread devient **4Ã— Ã  7Ã— plus rapide**
* Le mono-thread sature rapidement
* Le speedup augmente proportionnellement au nombre de workers
* Le contexte fixe du pool Ã©vite lâ€™overhead de crÃ©ation de threads

---

# ğŸ”® **Perspectives dâ€™Ã©volution**

* Passage Ã  **epoll** + threads hybrides
* Version **multi-processus** avec `fork()` + mÃ©moire partagÃ©e
* ImplÃ©mentation **lock-free MPMC**
* IntÃ©gration Docker & Kubernetes
* Monitoring Prometheus + Grafana

---

# ğŸ“œ Licence

Projet acadÃ©mique â€” diffusion et rÃ©utilisation autorisÃ©es dans un cadre pÃ©dagogique.

---



